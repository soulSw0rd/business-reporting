#!/usr/bin/env python3

"""
Prediction Engine
Moteur de pr√©diction ML pour l'analyse de profitabilit√© des traders crypto
Auteur: Crypto-Tracker Team
Date: 2025-01-08
Version: 1.0.0
"""

import numpy as np
import pandas as pd
import pickle
import logging
from pathlib import Path
from typing import Dict, Any, Tuple, Optional, List
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from .config_manager import get_config

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CryptoTraderPredictor:
    """
    CryptoTraderPredictor - Moteur de pr√©diction de profitabilit√© des traders
    
    RESPONSABILIT√â : Pr√©diction de la profitabilit√© future des traders crypto
    UTILISATION : Analyse des performances traders avec contexte march√©
    
    FONCTIONNALIT√âS :
    - Pr√©dictions court terme (7 jours) et long terme (30 jours)
    - Feature engineering automatique
    - Mod√®les Random Forest optimis√©s
    - √âvaluation de confiance des pr√©dictions
    - Gestion automatique des mod√®les pr√©-entra√Æn√©s
    """
    
    def __init__(self, model_path: Optional[str] = None):
        """
        OBJECTIF : Initialisation du moteur de pr√©diction
        
        PARAM√àTRES :
        - model_path (str, optional) : Chemin vers les mod√®les pr√©-entra√Æn√©s
        
        LOGIQUE :
        1. Chargement de la configuration
        2. Initialisation des mod√®les et scalers
        3. Tentative de chargement des mod√®les existants
        4. Configuration des param√®tres ML
        """
        self.config = get_config("ml")
        self.model_path = Path(model_path or self.config["model_path"])
        
        # Mod√®les pour diff√©rents horizons temporels
        self.model_7d = None
        self.model_30d = None
        self.scaler = StandardScaler()
        
        # √âtat d'entra√Ænement
        self.is_trained = False
        self.model_metadata = {}
        
        # Param√®tres ML
        self.n_estimators = 100
        self.random_state = self.config.get("random_state", 42)
        self.test_size = self.config.get("test_size", 0.2)
        self.confidence_threshold = self.config.get("confidence_threshold", 0.75)
        
        # Tentative de chargement des mod√®les existants
        self._load_existing_models()
        
        logger.info("CryptoTraderPredictor initialis√©")
    
    def _load_existing_models(self) -> bool:
        """
        OBJECTIF : Chargement des mod√®les pr√©-entra√Æn√©s depuis le disque
        
        RETOURNE :
        - bool : True si mod√®les charg√©s avec succ√®s
        
        LOGIQUE :
        1. V√©rification de l'existence des fichiers mod√®les
        2. Chargement des mod√®les RandomForest
        3. Chargement du scaler
        4. Chargement des m√©tadonn√©es
        """
        try:
            model_7d_path = self.model_path / "crypto_predictor_7d.pkl"
            model_30d_path = self.model_path / "crypto_predictor_30d.pkl"
            scaler_path = self.model_path / "scaler.pkl"
            metadata_path = self.model_path / "model_metadata.json"
            
            if all(p.exists() for p in [model_7d_path, model_30d_path, scaler_path]):
                # Chargement des mod√®les
                with open(model_7d_path, 'rb') as f:
                    self.model_7d = pickle.load(f)
                
                with open(model_30d_path, 'rb') as f:
                    self.model_30d = pickle.load(f)
                
                with open(scaler_path, 'rb') as f:
                    self.scaler = pickle.load(f)
                
                # Chargement des m√©tadonn√©es si disponibles
                if metadata_path.exists():
                    import json
                    with open(metadata_path, 'r') as f:
                        self.model_metadata = json.load(f)
                
                self.is_trained = True
                logger.info("Mod√®les pr√©-entra√Æn√©s charg√©s avec succ√®s")
                return True
                
        except Exception as e:
            logger.warning(f"Impossible de charger les mod√®les existants: {e}")
        
        return False
    
    def prepare_features(self, trader_data: Dict[str, Any], market_data: Dict[str, Any]) -> np.ndarray:
        """
        OBJECTIF : Pr√©paration des features pour la pr√©diction ML
        
        PARAM√àTRES :
        - trader_data (dict) : Donn√©es du trader {address, pnl_7d, win_rate, etc.}
        - market_data (dict) : Contexte march√© {btc_price, fear_greed, etc.}
        
        RETOURNE :
        - np.ndarray : Features normalis√©es pr√™tes pour la pr√©diction
        
        LOGIQUE :
        1. Extraction des m√©triques trader (PnL, win rate, exposition)
        2. Extraction des m√©triques march√© (prix BTC, sentiment, funding)
        3. Feature engineering (ratios, tendances)
        4. Normalisation et formatage pour le mod√®le
        """
        features = []
        
        # === FEATURES TRADER ===
        # Performance financi√®re
        pnl_7d = float(trader_data.get('pnl_7d', 0))
        pnl_30d = float(trader_data.get('pnl_30d', 0))
        features.extend([pnl_7d, pnl_30d])
        
        # M√©triques de trading
        win_rate = float(trader_data.get('win_rate', 0.5))
        long_percentage = float(trader_data.get('long_percentage', 50))
        features.extend([win_rate, long_percentage])
        
        # Features d√©riv√©es trader
        pnl_ratio = pnl_7d / max(abs(pnl_30d), 1)  # √âviter division par z√©ro
        risk_score = (100 - long_percentage) / 100  # Score de risque bas√© sur exposition
        features.extend([pnl_ratio, risk_score])
        
        # === FEATURES MARCH√â ===
        # Prix et volatilit√© Bitcoin
        btc_price = float(market_data.get('coingecko_btc', {}).get('price', 50000))
        btc_normalized = btc_price / 100000  # Normalisation approximative
        features.extend([btc_price, btc_normalized])
        
        # Sentiment de march√©
        fear_greed = float(market_data.get('fear_and_greed_index', {}).get('value', 50))
        fear_greed_normalized = fear_greed / 100
        features.extend([fear_greed, fear_greed_normalized])
        
        # Taux de financement
        funding_rate = float(market_data.get('funding_rates', {}).get('BTCUSDT', {}).get('last_funding_rate', 0))
        funding_normalized = funding_rate * 10000  # Amplification pour visibilit√©
        features.extend([funding_rate, funding_normalized])
        
        # === FEATURES CONTEXTUELLES ===
        # Interaction trader-march√©
        trader_market_alignment = win_rate * fear_greed_normalized
        market_risk_factor = abs(funding_normalized) * (1 - fear_greed_normalized)
        features.extend([trader_market_alignment, market_risk_factor])
        
        # Conversion en array numpy et reshape pour pr√©diction
        features_array = np.array(features, dtype=np.float32)
        
        # Gestion des valeurs manquantes ou infinies
        features_array = np.nan_to_num(features_array, nan=0.0, posinf=1.0, neginf=-1.0)
        
        return features_array.reshape(1, -1)
    
    def generate_training_data(self, n_samples: int = 1000) -> pd.DataFrame:
        """
        OBJECTIF : G√©n√©ration de donn√©es d'entra√Ænement simul√©es r√©alistes
        
        PARAM√àTRES :
        - n_samples (int) : Nombre d'√©chantillons √† g√©n√©rer
        
        RETOURNE :
        - pd.DataFrame : Dataset d'entra√Ænement avec features et targets
        
        LOGIQUE :
        1. G√©n√©ration de features traders r√©alistes
        2. G√©n√©ration de contexte march√© vari√©
        3. Calcul des labels de profitabilit√© avec logique m√©tier
        4. Ajout de bruit pour simuler l'incertitude r√©elle
        """
        np.random.seed(self.random_state)
        data = []
        
        logger.info(f"G√©n√©ration de {n_samples} √©chantillons d'entra√Ænement")
        
        for i in range(n_samples):
            # === G√âN√âRATION FEATURES TRADER ===
            # PnL avec distribution r√©aliste (la plupart perdent de l'argent)
            pnl_7d = np.random.normal(0, 1000) - 200  # Biais n√©gatif
            pnl_30d = np.random.normal(0, 3000) - 500  # Biais n√©gatif plus fort
            
            # Win rate r√©aliste (entre 30% et 80%)
            win_rate = np.random.beta(2, 3) * 0.5 + 0.3  # Distribution r√©aliste
            
            # Exposition long/short
            long_percentage = np.random.uniform(20, 80)
            
            # === G√âN√âRATION CONTEXTE MARCH√â ===
            # Prix Bitcoin avec volatilit√©
            btc_price = np.random.uniform(30000, 80000)
            
            # Fear & Greed avec tendance centrale
            fear_greed = np.random.beta(2, 2) * 100  # Distribution en cloche
            
            # Funding rate r√©aliste
            funding_rate = np.random.normal(0, 0.0001)
            
            # === CALCUL FEATURES D√âRIV√âES ===
            pnl_ratio = pnl_7d / max(abs(pnl_30d), 1)
            risk_score = (100 - long_percentage) / 100
            btc_normalized = btc_price / 100000
            fear_greed_normalized = fear_greed / 100
            funding_normalized = funding_rate * 10000
            trader_market_alignment = win_rate * fear_greed_normalized
            market_risk_factor = abs(funding_normalized) * (1 - fear_greed_normalized)
            
            # === LOGIQUE DE PROFITABILIT√â ===
            # Probabilit√© de base bas√©e sur les performances pass√©es
            base_prob_7d = 0.5 + (pnl_7d / 5000) + (win_rate - 0.5) * 0.4
            base_prob_30d = 0.5 + (pnl_30d / 10000) + (win_rate - 0.5) * 0.3
            
            # Influence du march√©
            market_boost = (fear_greed - 50) / 200  # March√© bullish = boost
            funding_penalty = abs(funding_rate) * 1000  # Funding √©lev√© = risque
            
            # Probabilit√©s finales avec bruit
            prob_7d = base_prob_7d + market_boost - funding_penalty + np.random.normal(0, 0.1)
            prob_30d = base_prob_30d + market_boost * 0.5 - funding_penalty + np.random.normal(0, 0.1)
            
            # Limitation des probabilit√©s
            prob_7d = np.clip(prob_7d, 0.05, 0.95)
            prob_30d = np.clip(prob_30d, 0.05, 0.95)
            
            # Conversion en labels binaires
            profitable_7d = 1 if prob_7d > 0.5 else 0
            profitable_30d = 1 if prob_30d > 0.5 else 0
            
            # Stockage de l'√©chantillon
            data.append({
                # Features brutes
                'pnl_7d': pnl_7d,
                'pnl_30d': pnl_30d,
                'win_rate': win_rate,
                'long_percentage': long_percentage,
                'btc_price': btc_price,
                'fear_greed': fear_greed,
                'funding_rate': funding_rate,
                # Features d√©riv√©es
                'pnl_ratio': pnl_ratio,
                'risk_score': risk_score,
                'btc_normalized': btc_normalized,
                'fear_greed_normalized': fear_greed_normalized,
                'funding_normalized': funding_normalized,
                'trader_market_alignment': trader_market_alignment,
                'market_risk_factor': market_risk_factor,
                # Targets
                'profitable_7d': profitable_7d,
                'profitable_30d': profitable_30d,
                # M√©tadonn√©es
                'prob_7d': prob_7d,
                'prob_30d': prob_30d
            })
        
        df = pd.DataFrame(data)
        logger.info(f"Dataset g√©n√©r√©: {len(df)} √©chantillons, {len(df.columns)} features")
        
        return df
    
    def train_models(self, training_data: Optional[pd.DataFrame] = None) -> Dict[str, Any]:
        """
        OBJECTIF : Entra√Ænement des mod√®les Random Forest pour 7 et 30 jours
        
        PARAM√àTRES :
        - training_data (pd.DataFrame, optional) : Donn√©es d'entra√Ænement
        
        RETOURNE :
        - dict : M√©triques d'√©valuation des mod√®les
        
        LOGIQUE :
        1. G√©n√©ration des donn√©es si non fournies
        2. Pr√©paration des features et targets
        3. Division train/test
        4. Entra√Ænement des mod√®les RandomForest
        5. √âvaluation et sauvegarde des mod√®les
        """
        if training_data is None:
            training_samples = self.config.get("training_samples", 1000)
            training_data = self.generate_training_data(training_samples)
        
        logger.info("D√©but de l'entra√Ænement des mod√®les")
        
        # === PR√âPARATION DES DONN√âES ===
        feature_columns = [
            'pnl_7d', 'pnl_30d', 'win_rate', 'long_percentage', 'btc_price',
            'fear_greed', 'funding_rate', 'pnl_ratio', 'risk_score',
            'btc_normalized', 'fear_greed_normalized', 'funding_normalized',
            'trader_market_alignment', 'market_risk_factor'
        ]
        
        X = training_data[feature_columns].values
        y_7d = training_data['profitable_7d'].values
        y_30d = training_data['profitable_30d'].values
        
        # Normalisation des features
        X_scaled = self.scaler.fit_transform(X)
        
        # Division train/test
        X_train, X_test, y_7d_train, y_7d_test = train_test_split(
            X_scaled, y_7d, test_size=self.test_size, random_state=self.random_state
        )
        _, _, y_30d_train, y_30d_test = train_test_split(
            X_scaled, y_30d, test_size=self.test_size, random_state=self.random_state
        )
        
        # === ENTRA√éNEMENT MOD√àLE 7 JOURS ===
        logger.info("Entra√Ænement du mod√®le 7 jours")
        self.model_7d = RandomForestClassifier(
            n_estimators=self.n_estimators,
            random_state=self.random_state,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            class_weight='balanced'
        )
        self.model_7d.fit(X_train, y_7d_train)
        
        # === ENTRA√éNEMENT MOD√àLE 30 JOURS ===
        logger.info("Entra√Ænement du mod√®le 30 jours")
        self.model_30d = RandomForestClassifier(
            n_estimators=self.n_estimators,
            random_state=self.random_state,
            max_depth=12,
            min_samples_split=5,
            min_samples_leaf=2,
            class_weight='balanced'
        )
        self.model_30d.fit(X_train, y_30d_train)
        
        # === √âVALUATION ===
        y_7d_pred = self.model_7d.predict(X_test)
        y_30d_pred = self.model_30d.predict(X_test)
        
        accuracy_7d = accuracy_score(y_7d_test, y_7d_pred)
        accuracy_30d = accuracy_score(y_30d_test, y_30d_pred)
        
        # M√©tadonn√©es des mod√®les
        self.model_metadata = {
            'training_date': pd.Timestamp.now().isoformat(),
            'training_samples': len(training_data),
            'feature_columns': feature_columns,
            'accuracy_7d': accuracy_7d,
            'accuracy_30d': accuracy_30d,
            'test_size': self.test_size,
            'n_estimators': self.n_estimators,
            'random_state': self.random_state
        }
        
        self.is_trained = True
        
        # Sauvegarde automatique
        self._save_models()
        
        logger.info(f"Entra√Ænement termin√© - Pr√©cision 7j: {accuracy_7d:.3f}, 30j: {accuracy_30d:.3f}")
        
        return {
            'accuracy_7d': accuracy_7d,
            'accuracy_30d': accuracy_30d,
            'samples_count': len(training_data),
            'feature_importance_7d': dict(zip(feature_columns, self.model_7d.feature_importances_)),
            'feature_importance_30d': dict(zip(feature_columns, self.model_30d.feature_importances_))
        }
    
    def predict_profitability(self, trader_data: Dict[str, Any], market_data: Dict[str, Any], 
                            horizon_days: int = 7) -> Dict[str, Any]:
        """
        OBJECTIF : Pr√©diction de la profitabilit√© d'un trader
        
        PARAM√àTRES :
        - trader_data (dict) : Donn√©es du trader
        - market_data (dict) : Contexte march√©
        - horizon_days (int) : Horizon de pr√©diction (7 ou 30 jours)
        
        RETOURNE :
        - dict : R√©sultat de pr√©diction complet
        
        LOGIQUE :
        1. V√©rification de l'√©tat d'entra√Ænement
        2. Pr√©paration des features
        3. Pr√©diction avec le mod√®le appropri√©
        4. Interpr√©tation et formatage du r√©sultat
        """
        if not self.is_trained:
            logger.info("Mod√®les non entra√Æn√©s, lancement de l'entra√Ænement")
            training_results = self.train_models()
            logger.info(f"Entra√Ænement termin√©: {training_results}")
        
        try:
            # Pr√©paration des features
            features = self.prepare_features(trader_data, market_data)
            features_scaled = self.scaler.transform(features)
            
            # Pr√©dictions pour les deux horizons
            prob_7d = self.model_7d.predict_proba(features_scaled)[0][1]
            prob_30d = self.model_30d.predict_proba(features_scaled)[0][1]
            
            # Interpr√©tation des r√©sultats
            result_7d = self._interpret_prediction(prob_7d, 7)
            result_30d = self._interpret_prediction(prob_30d, 30)
            
            # Calcul de la confiance globale
            confidence = (prob_7d + prob_30d) / 2 * 100
            
            result = {
                'prediction_7d': prob_7d * 100,  # Pourcentage
                'prediction_30d': prob_30d * 100,  # Pourcentage
                'confidence': confidence,
                'interpretation_7d': result_7d,
                'interpretation_30d': result_30d,
                'trader_address': trader_data.get('address', 'Unknown'),
                'timestamp': pd.Timestamp.now().isoformat()
            }
            
            logger.info(f"Pr√©diction compl√®te: 7j={prob_7d:.3f}, 30j={prob_30d:.3f}")
            
            return result
            
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction: {e}")
            return {
                'prediction_7d': 0.0,
                'prediction_30d': 0.0,
                'confidence': 0.0,
                'interpretation_7d': f"Erreur: {str(e)}",
                'interpretation_30d': f"Erreur: {str(e)}",
                'trader_address': trader_data.get('address', 'Unknown'),
                'timestamp': pd.Timestamp.now().isoformat()
            }
    
    def _interpret_prediction(self, probability: float, horizon_days: int) -> str:
        """
        OBJECTIF : Interpr√©tation textuelle de la probabilit√© de profit
        
        PARAM√àTRES :
        - probability (float) : Probabilit√© de profit (0-1)
        - horizon_days (int) : Horizon temporel
        
        RETOURNE :
        - str : Interpr√©tation textuelle avec √©mojis
        
        LOGIQUE :
        1. Classification par seuils de probabilit√©
        2. Adaptation du message selon l'horizon
        3. Ajout d'√©mojis pour clart√© visuelle
        """
        if probability > 0.8:
            return f"üü¢ Tr√®s fortement profitable √† {horizon_days} jours"
        elif probability > 0.7:
            return f"üü¢ Fortement profitable √† {horizon_days} jours"
        elif probability > 0.6:
            return f"üü° Potentiellement profitable √† {horizon_days} jours"
        elif probability > 0.4:
            return f"üü† Incertain √† {horizon_days} jours"
        elif probability > 0.3:
            return f"üî¥ Peu probable d'√™tre profitable √† {horizon_days} jours"
        else:
            return f"üî¥ Tr√®s peu probable d'√™tre profitable √† {horizon_days} jours"
    
    def _save_models(self) -> bool:
        """
        OBJECTIF : Sauvegarde des mod√®les entra√Æn√©s sur disque
        
        RETOURNE :
        - bool : True si sauvegarde r√©ussie
        
        LOGIQUE :
        1. Cr√©ation du dossier de destination
        2. Sauvegarde des mod√®les RandomForest
        3. Sauvegarde du scaler
        4. Sauvegarde des m√©tadonn√©es
        """
        try:
            # Cr√©ation du dossier
            self.model_path.mkdir(parents=True, exist_ok=True)
            
            # Sauvegarde des mod√®les
            with open(self.model_path / "crypto_predictor_7d.pkl", 'wb') as f:
                pickle.dump(self.model_7d, f)
            
            with open(self.model_path / "crypto_predictor_30d.pkl", 'wb') as f:
                pickle.dump(self.model_30d, f)
            
            with open(self.model_path / "scaler.pkl", 'wb') as f:
                pickle.dump(self.scaler, f)
            
            # Sauvegarde des m√©tadonn√©es
            import json
            with open(self.model_path / "model_metadata.json", 'w') as f:
                json.dump(self.model_metadata, f, indent=2)
            
            logger.info(f"Mod√®les sauvegard√©s dans {self.model_path}")
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde: {e}")
            return False
    
    def get_feature_importance(self, horizon_days: int = 7) -> Dict[str, float]:
        """
        OBJECTIF : R√©cup√©ration de l'importance des features
        
        PARAM√àTRES :
        - horizon_days (int) : Horizon temporel (7 ou 30)
        
        RETOURNE :
        - dict : Importance des features par nom
        
        LOGIQUE :
        1. S√©lection du mod√®le appropri√©
        2. Extraction des importances
        3. Formatage avec noms des features
        """
        if not self.is_trained:
            return {}
        
        model = self.model_7d if horizon_days == 7 else self.model_30d
        if model is None:
            return {}
        
        feature_names = self.model_metadata.get('feature_columns', [])
        importances = model.feature_importances_
        
        return dict(zip(feature_names, importances))
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        OBJECTIF : R√©cup√©ration des informations sur les mod√®les
        
        RETOURNE :
        - dict : M√©tadonn√©es compl√®tes des mod√®les
        """
        return {
            'is_trained': self.is_trained,
            'metadata': self.model_metadata,
            'model_path': str(self.model_path),
            'config': self.config
        } 